{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "3.02 - Train word embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olivermueller/aml4ta-2021/blob/main/Session_03/3_02_Train_word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4drq3zd0Yl6"
      },
      "source": [
        "# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TagnCxW00UNH"
      },
      "source": [
        "# Set up Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_ajKrg-FU9T"
      },
      "source": [
        "# Install packages\n",
        "!pip install pymysql"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkB8pITZ0dYo"
      },
      "source": [
        "# <font color=\"#003660\">Week 3: Word Embeddings</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbNXbRF50d1S"
      },
      "source": [
        "# <font color=\"#003660\">Notebook 2: Train Your Own Word Embeddings</font>\n",
        "\n",
        "<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n",
        "\n",
        "<p>\n",
        "<center>\n",
        "<div>\n",
        "    <font color=\"#085986\"><b>By the end of this lesson, you ...</b><br><br>\n",
        "        ... are able to train your own word embeddings from data.\n",
        "    </font>\n",
        "</div>\n",
        "</center>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpXD2GY90UNN"
      },
      "source": [
        "# Import packages\n",
        "\n",
        "As always, we first need to load a number of required Python packages:\n",
        "- `pandas` provides high-performance, easy-to-use data structures and data analysis tools.\n",
        "- `SQLAlchemy`, together with `pymysql`, allows to communicate with SQL databases.\n",
        "- `getpass` provides function to safely enter passwords.\n",
        "- `spacy` offers industrial-strength natural language processing.\n",
        "- `gensim` is a fast library for training of vector embeddings and topic models.\n",
        "- `sklearn` is the de-facto standard machine learning package in Python.\n",
        "- `plotly` is a library for creating interactive plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QNgYvVea0UNN"
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sqlalchemy import create_engine\n",
        "import getpass\n",
        "import spacy\n",
        "from gensim.models import word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpnK3Eb00UNX"
      },
      "source": [
        "# How are word embeddings learned?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiPasIBY0UNX"
      },
      "source": [
        "Word embeddings can be learned from a given corpus by training a simple shallow neural network to predict a target word from its surrounding words in a sentence (this is called the CBOW architecture). The hidden layer of the neural network represents the actual embedding vectors. (Mikolov et al., 2013)\n",
        "\n",
        "<br>\n",
        "\n",
        "<center><img width=512 src=\"https://git.uni-paderborn.de/data.analytics.teaching/aml4ta-2020/-/raw/master/week_3/images/cbow.png\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGxkqnFe0UNX"
      },
      "source": [
        "# Load documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmaWF3ER0UNX"
      },
      "source": [
        "We will work with a dataset consisitng of approx. 130.000 wine reviews written by professional sommeliers. Each review has review text and rating and additional meta data about the wine, such as, variety, location, winery, or price. You can find the original dataset here: https://www.kaggle.com/zynicide/wine-reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqk69P-S0UNX"
      },
      "source": [
        "# Get credentials\n",
        "user = input(\"Username: \")\n",
        "passwd = getpass.getpass(\"Password: \")\n",
        "server = input(\"Server: \")\n",
        "db = input(\"Database: \")\n",
        "\n",
        "# Create an engine instance (SQLAlchemy)\n",
        "engine = create_engine(\"mysql+pymysql://{}:{}@{}/{}\".format(user, passwd ,server, db))\n",
        "\n",
        "# Define SQL query\n",
        "sql_query = \"SELECT * FROM WineDataset\"\n",
        "\n",
        "# Query dataset (pandas)\n",
        "corpus = pd.read_sql(sql=sql_query, con=engine)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFD6jgiF0UNY"
      },
      "source": [
        "# Preprocess documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4nBClQR0UNY"
      },
      "source": [
        "Perform some standard natural language preprocessing steps with spaCy. As word embeddings are best trained on sentences, not documents, we first cut the reviews into sentences and then preprocess them sentence by sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "w-TLOTX50UNY"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'tagger'])\n",
        "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "\n",
        "sentences = []\n",
        "for i, entry in corpus.iterrows():\n",
        "    tokens = nlp(entry['description'])\n",
        "    for sentence in tokens.sents:\n",
        "        tokens_to_keep = []\n",
        "        for t in sentence:\n",
        "            if t.is_alpha: # only consider alphanumerical tokens\n",
        "                tokens_to_keep.append(t.text.lower()) # append lowercased word\n",
        "        sentences.append(tokens_to_keep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqcc-uex0UNZ"
      },
      "source": [
        "Save sentences to disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "utcB3K1G0UNZ"
      },
      "source": [
        "with open(\"/content/gdrive/MyDrive/Colab_Notebooks/AMLTA2021/Session_03/data/sentences.pkl\", \"wb\") as output:\n",
        "    pickle.dump(sentences, output, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEIjL6fC0UNZ"
      },
      "source": [
        "Load sentences from disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lhtt9nxa0UNZ"
      },
      "source": [
        "with open(\"/content/gdrive/MyDrive/Colab_Notebooks/AMLTA2021/Session_03/data/sentences.pkl\", \"rb\") as input:\n",
        "    sentences = pickle.load(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwMrrusB0UNZ"
      },
      "source": [
        "How many sentences do we have?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMk9OqVP0UNZ"
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTzW5f3_0UNa"
      },
      "source": [
        "Look at the first one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "q_QskZol0UNa"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRjy3qYn0UNa"
      },
      "source": [
        "# Learn word embeddings from data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Nz2tVV0UNa"
      },
      "source": [
        "We use Gensim's implementation of word2vec to create word embeddings. See https://radimrehurek.com/gensim/models/keyedvectors.html#module-gensim.models.keyedvectors for documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcQEgmXF0UNa"
      },
      "source": [
        "Create a model with 300 dimensions and a context window of 6 words. Only consider words that appear at least in 2 documents. Use 6 CPU cores for estimating the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QgwWepqb0UNa"
      },
      "source": [
        "model = word2vec.Word2Vec(sentences, size=300, window = 6, min_count = 2, workers=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKUV1Kd00UNa"
      },
      "source": [
        "Get word vectors from model and store as file for later reuse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IgG_6jaZ0UNa"
      },
      "source": [
        "word_vectors = model.wv\n",
        "word_vectors.save_word2vec_format(\"/content/gdrive/MyDrive/Colab_Notebooks/AMLTA2021/Session_03/data/wine_300dim_10minwords_4context\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g1G58UA0UNb"
      },
      "source": [
        "Load word vectors from file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KsSUXtqk0UNb"
      },
      "source": [
        "word_vectors = KeyedVectors.load_word2vec_format(\"/content/gdrive/MyDrive/Colab_Notebooks/AMLTA2021/Session_03/data/wine_300dim_10minwords_4context\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opj1RKV_0UNb"
      },
      "source": [
        "# Explore word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTqNH4C-0UNb"
      },
      "source": [
        "Retrieve most similar words to a given word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6C17oBpp0UNb"
      },
      "source": [
        "word_vectors.most_similar(\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yCYSauoD0UNb"
      },
      "source": [
        "word_vectors.most_similar(\"white\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuP3ubCn0UNc"
      },
      "source": [
        "Which word doesn't belong to the set?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fuaPa_520UNc"
      },
      "source": [
        "word_vectors.doesnt_match([\"red\", \"raspberry\", \"tanin\", \"peach\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EYRxgd5P0UNc"
      },
      "source": [
        "word_vectors.doesnt_match([\"white\", \"cherry\", \"cantaloupe\", \"citrus\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-osmaKEv0UNc"
      },
      "source": [
        "Let's look at some analogies using \"King – Man + Woman = Queen\"-style vector arithmetic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdWXHwgx0UNc"
      },
      "source": [
        "Fig - Red + White = ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KkhETmQy0UNc"
      },
      "source": [
        "word_vectors.most_similar(positive=['fig', 'white'], negative=['red'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv_8FBe30UNd"
      },
      "source": [
        "Honey - White + Red = ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "s1GD8puB0UNd"
      },
      "source": [
        "word_vectors.most_similar(positive=['honey', 'red'], negative=['white'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RktVMiFc0UNd"
      },
      "source": [
        "Riesling - White + Red = ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "I60IAqsX0UNd"
      },
      "source": [
        "word_vectors.most_similar(positive=['riesling', 'red'], negative=['white'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_79S_bDC0UNd"
      },
      "source": [
        "# Visualize embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx8CfMfI0UNd"
      },
      "source": [
        "Get a list of all the words in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Gx6ndOIA0UNd"
      },
      "source": [
        "vocab = list(word_vectors.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezf-0WXm0UNe"
      },
      "source": [
        "Retrieve the associated word embedding vectors from the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OrfDB_s40UNe"
      },
      "source": [
        "X = word_vectors[vocab]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNLw0kPB0UNe"
      },
      "source": [
        "Reduce the dimensionality of the data with PCA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Am2TOjDu0UNe"
      },
      "source": [
        "X_pca = PCA(n_components=2).fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_yIxxpd0UNf"
      },
      "source": [
        "Reformat data, add similarity to a \"seed\" word, (filter to most similar words), and create an interactive scatterplot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyuCr_qh0UNf"
      },
      "source": [
        "pca_df = pd.DataFrame(X_pca, index=vocab, columns=['x', 'y'])\n",
        "pca_df[\"word\"] = vocab\n",
        "\n",
        "seed = \"oak\"\n",
        "pca_df[\"sim\"] = 0\n",
        "\n",
        "for word, sim in word_vectors.most_similar(seed, topn=100):\n",
        "    pca_df.loc[word, 'sim'] = sim\n",
        "\n",
        "# filter to 100 most similar words?\n",
        "pca_df = pca_df[pca_df[\"sim\"]>0]\n",
        "\n",
        "fig = px.scatter(pca_df, x=\"x\", y=\"y\", color=\"sim\", \n",
        "                 hover_data=[\"word\"], \n",
        "                 range_x = [-11, 11], range_y = [-11, 11],\n",
        "                 opacity = 0.2, color_continuous_scale='agsunset_r')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxuYC6ZoRSEM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}