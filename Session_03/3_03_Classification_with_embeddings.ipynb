{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "3.03 - Classification with embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olivermueller/aml4ta-2021/blob/main/Session_03/3_03_Classification_with_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJrKCbjZsqpo"
      },
      "source": [
        "# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pblMcujrVt7-"
      },
      "source": [
        "# Set up Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NpTS4Z2Vvzy"
      },
      "source": [
        "# Install packages\n",
        "!pip install pymysql"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-DU0hkyVyPi"
      },
      "source": [
        "# <font color=\"#003660\">Week 3: Word Embeddings</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhy42GjRV3ON"
      },
      "source": [
        "# <font color=\"#003660\">Notebook 3: Classification with Word Embeddings</font>\n",
        "\n",
        "<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n",
        "\n",
        "<p>\n",
        "<center>\n",
        "<div>\n",
        "    <font color=\"#085986\"><b>By the end of this lesson, you will be able to...</b><br><br>\n",
        "        ... train a classifier with mean word embeddings as features.\n",
        "    </font>\n",
        "</div>\n",
        "</center>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6vVpwIFsqps"
      },
      "source": [
        "# Import packages\n",
        "\n",
        "As always, we first need to load a number of required Python packages:\n",
        "- `pandas` provides high-performance, easy-to-use data structures and data analysis tools.\n",
        "- `numpy` is a library adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
        "- `SQLAlchemy`, together with `pymysql`, allows to communicate with SQL databases.\n",
        "- `getpass` provides function to safely enter passwords.\n",
        "- `spacy` offers industrial-strength natural language processing.\n",
        "- `en_core_web_md` is a pre-trained Spacy model that has word embeddings included\n",
        "- `sklearn` is the de-facto standard machine learning package in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMrhkr83sqpt"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sqlalchemy import create_engine\n",
        "import getpass\n",
        "import spacy\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZd82t53sqpu"
      },
      "source": [
        "# Load documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsrCafxksqpv"
      },
      "source": [
        "We load our data from a MySQL database. For security reasons, we don't store the database credentials here; please have a look at Panda to get them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSIGfKcXsqpv"
      },
      "source": [
        "# Get credentials\n",
        "user = input(\"Username: \")\n",
        "passwd = getpass.getpass(\"Password: \")\n",
        "server = input(\"Server: \")\n",
        "db = input(\"Database: \")\n",
        "\n",
        "# Create an engine instance (SQLAlchemy)\n",
        "engine = create_engine(\"mysql+pymysql://{}:{}@{}/{}\".format(user, passwd ,server, db))\n",
        "\n",
        "# Define SQL query\n",
        "sql_query = \"SELECT * FROM WineDataset\"\n",
        "\n",
        "# Query dataset (pandas)\n",
        "corpus = pd.read_sql(sql=sql_query, con=engine)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NsIQrLiSEak"
      },
      "source": [
        "corpus.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v8oiPAcsqpx"
      },
      "source": [
        "# Preprocess documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7psnR5cmQLBx"
      },
      "source": [
        "Split data into training, validation, and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSObnTaWdgdM"
      },
      "source": [
        "training = corpus[corpus[\"testset\"] == 0]\n",
        "validation = training.iloc[80000:100000,]\n",
        "training = training.iloc[0:80000,]\n",
        "test = corpus[corpus[\"testset\"] == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m05pjMr8Rvxs"
      },
      "source": [
        "print(training.shape)\n",
        "print(validation.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clAMcveqPOjb"
      },
      "source": [
        "# Vectorize documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSrHVdoZsqpy"
      },
      "source": [
        "Instead of using a BoW model, we will vectorize the documents by computing the average word embeddings over all words of a document. For this, we will use the word embeddings we have trained on the wine dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9L1oJXkSflG"
      },
      "source": [
        "Convert the trained word embeddings to a format that Spacy understands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlutz00FHpln"
      },
      "source": [
        "!python -m spacy init-model en /content/gdrive/MyDrive/Colab_Notebooks/AMLTA2021/Session_03/data --vectors-loc /content/gdrive/MyDrive/Colab_Notebooks/AMLTA2021/Session_03/data/wine_300dim_10minwords_4context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWPHcopnSlT8"
      },
      "source": [
        "Load the custom embeddings and extract the mean word embeddings for each document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh4KVmP6sqpy"
      },
      "source": [
        "nlp = spacy.load(\"/content/gdrive/MyDrive/Colab_Notebooks/AMLTA2021/Session_03/data\")\n",
        "\n",
        "def spacy_prep(dataset):\n",
        "  vectors = []\n",
        "  dataset = dataset.to_dict(\"records\")\n",
        "  for i, entry in enumerate(dataset):\n",
        "      text = nlp(entry[u'description'])\n",
        "      vectors.append(text.vector)\n",
        "  return(np.array(vectors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4rKCZRs9tlj"
      },
      "source": [
        "X_training = spacy_prep(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyLoiearsqpz"
      },
      "source": [
        "X_training.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QTlJ4BDsqp3"
      },
      "source": [
        "Store the labels that we want to predict in a separate variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUpaU5Pgsqp3"
      },
      "source": [
        "y_training = training[\"verygood\"]\n",
        "y_training.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biwWaNjNsqp4"
      },
      "source": [
        "# Train classifier on training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTHaUsAosqp4"
      },
      "source": [
        "Fit a classifier with word embeddings as the features and wine quality (i.e., `verygood` variable) as the label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZkAh7oesqp4"
      },
      "source": [
        "clf = LogisticRegression(max_iter=1000).fit(X_training, y_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "663LU5XQsqp5"
      },
      "source": [
        "# Evaluate accuracy on validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8-z8rqVsqp6"
      },
      "source": [
        "Before trying to predict the labels for the official test set (on Kaggle), we evaluate the predictive accurcay of our model on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCZDzJOR51SZ"
      },
      "source": [
        "X_validation = spacy_prep(validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiUIhoK0sqp6"
      },
      "source": [
        "y_validation = validation[\"verygood\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4upAshmAsqp6"
      },
      "source": [
        "Call the predict function of our model with the validation data and calculate precision, recall and F1-score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ngkprkgsqp6"
      },
      "source": [
        "predictions_validation = clf.predict(X_validation)\n",
        "print(metrics.classification_report(y_validation, predictions_validation))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}