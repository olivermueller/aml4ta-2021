{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olivermueller/aml4ta-2021/blob/main/Session_08/08_sequence2sequence_FULL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctvwSGh1zgQA"
      },
      "outputs": [],
      "source": [
        "# IF USING GOOGLE COLABORATORY -> RUN FIRST!!!\n",
        "# OTHERWISE -> IGNORE ;-)\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!pip install pymysql"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z74qRQMfzgQF"
      },
      "source": [
        "# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n",
        "# <font color=\"#003660\">Lesson 8: Creating a Neural Translator with Sequence-to-Sequence Models</font>\n",
        "\n",
        "<center><br><img width=256 src=\"https://git.uni-paderborn.de/data.analytics.teaching/aml4ta-2020/-/raw/master/resources/dag.png\"/><br></center>\n",
        "\n",
        "<p>\n",
        "<center>\n",
        "<div>\n",
        "    <font color=\"#085986\"><b>By the end of this lesson, you will be able to...</b><br><br>\n",
        "        ... understand the inner workings of sequence-to-sequence architectures;<br>\n",
        "        ... implement your own sequence-to-sequence models.<br>\n",
        "    </font>\n",
        "</div>\n",
        "</center>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0oKa2M4zgQH"
      },
      "source": [
        "<center><img width=100 src=\"https://git.uni-paderborn.de/data.analytics.teaching/aml4ta-2020/-/raw/master/resources/tip.png\"></center>\n",
        "\n",
        "<p><center><font color=\"red\"><strong><i>This entire tutorial is based on the implementations by <a href=\"https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\">Robertson (n.d.)</a> and <a href=\"https://github.com/bentrevett/pytorch-seq2seq/blob/master/2%20-%20Learning%20Phrase%20Representations%20using%20RNN%20Encoder-Decoder%20for%20Statistical%20Machine%20Translation.ipynb\">Trevett (n.d.)</a> of the architecture proposed by Cho et al. (2014).</i></strong></font></center></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar3IB-q-zgQH"
      },
      "source": [
        "# 1. What is a Sequence-to-Sequence Model?\n",
        "\n",
        "\n",
        "## 1.1 General Idea\n",
        "\n",
        "<table class=\"image\">\n",
        "<center>\n",
        "<caption align=\"bottom\">(Lane et al., 2019,  p.318)</caption>\n",
        "<tr><td><img width=540 src='https://git.uni-paderborn.de/data.analytics.teaching/aml4ta-2020/-/raw/master/week_6/images/seq2seq.png'></td></tr>\n",
        "</center>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_5Bb5QCzgQI"
      },
      "source": [
        "## 1.2 Applications\n",
        "<center><img width=100 src=\"https://git.uni-paderborn.de/data.analytics.teaching/aml4ta-2020/-/raw/master/resources/question.png\"></center>\n",
        "\n",
        "<p><center><b>What are possible applications of sequence-to-sequence models?<br>What are they good for?</b></center></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCcEp38WzgQJ"
      },
      "source": [
        "# 2. Dataset\n",
        "\n",
        "<p>For this tutorial, we will use, akin to <a href=\"https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\">Robertson (n.d.)</a>, a dataset provided by <a href=\"https://tatoeba.org/eng/\">Tatoeba.</a></p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxe3aoBVzgQJ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "################\n",
        "# Load dataset #\n",
        "################\n",
        "\n",
        "# Import\n",
        "import re\n",
        "import getpass\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Get credentials\n",
        "user = input(\"Username: \")\n",
        "host = input(\"Host: \")\n",
        "db = input(\"Database: \")\n",
        "passwd = getpass.getpass(\"Password: \")\n",
        "\n",
        "# Create an engine instance (SQLAlchemy)\n",
        "engine = create_engine(\"mysql+pymysql://{}:{}@{}/{}\".format(user, passwd, host, db))\n",
        "\n",
        "# Define SQL query\n",
        "sql_query = \"SELECT english, german FROM TatoebaEnglishGerman\"\n",
        "\n",
        "# Query dataset (pandas)\n",
        "data = pd.read_sql(sql=sql_query, con=engine)\n",
        "\n",
        "# Sample\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9Qx67F0zgQK"
      },
      "outputs": [],
      "source": [
        "###################\n",
        "# Explore dataset #\n",
        "###################\n",
        "\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klEll1rGzgQL"
      },
      "source": [
        "<p>For the sake of this tutorial, the documents were already preprocessed and have a maximum length of 10 tokens. However, some more preprocessing is required before we can get started!</p>\n",
        "\n",
        "<table class=\"image\">\n",
        "<center>\n",
        "<caption align=\"bottom\">(Lane et al., 2019,  p.319)</caption>\n",
        "<tr><td><img width=768 src='https://git.uni-paderborn.de/data.analytics.teaching/aml4ta-2020/-/raw/master/week_6/images/preprocessing.png'></td></tr>\n",
        "</center>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHHmgwP-zgQL"
      },
      "outputs": [],
      "source": [
        "#################\n",
        "# Preprocessing #\n",
        "#################\n",
        "\n",
        "# Import\n",
        "import re\n",
        "\n",
        "def preprocessing(doc):\n",
        "    \n",
        "    # Tokenize\n",
        "    doc = re.findall(r'\\w+', doc)\n",
        "    \n",
        "    # Add <sos> token (start of sentence)\n",
        "    doc.insert(0, '<sos>')\n",
        "    \n",
        "    # Add <eos> token (end of sentence)\n",
        "    doc.insert(len(doc), '<eos>')\n",
        "    \n",
        "    return doc\n",
        "\n",
        "data.english = data.english.apply(preprocessing)\n",
        "data.german = data.german.apply(preprocessing)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fIeV2R4zgQM"
      },
      "outputs": [],
      "source": [
        "#################\n",
        "# Split dataset #\n",
        "# 80% / 5% / 5% #\n",
        "#################\n",
        "\n",
        "# Import\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train / Test split\n",
        "train, test = train_test_split(data,\n",
        "                               test_size=0.1,\n",
        "                               random_state=42)\n",
        "test, val = train_test_split(test,\n",
        "                             test_size=0.5,\n",
        "                             random_state=42)\n",
        "\n",
        "print(train.shape)\n",
        "print(val.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6CN_ti8zgQN"
      },
      "outputs": [],
      "source": [
        "######################\n",
        "# Build vocabularies #\n",
        "######################\n",
        "\n",
        "def vocabulary_generator(corpus):\n",
        "    \n",
        "    vocab = {\"<pad>\": 0, \"<unk>\": 1, \"<sos>\": 2, \"<eos>\": 3}\n",
        "    \n",
        "    for doc in corpus:\n",
        "        for token in doc:\n",
        "            if token not in vocab:\n",
        "                vocab[token] = len(vocab)+1\n",
        "                \n",
        "    return vocab\n",
        "    \n",
        "# Source vocabulary – i.e., English\n",
        "src_vocabulary = vocabulary_generator(train.english)\n",
        "\n",
        "# Target vocabulary – i.e., German\n",
        "trg_vocabulary = vocabulary_generator(train.german)\n",
        "\n",
        "print(len(src_vocabulary))\n",
        "print(len(trg_vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNjEzqmFzgQO"
      },
      "outputs": [],
      "source": [
        "#######################\n",
        "# Vectorize documents #\n",
        "#######################\n",
        "\n",
        "# Import\n",
        "import torch\n",
        "\n",
        "MAX_LENGTH = 12\n",
        "\n",
        "def document_vectorizer(corpus, vocab):\n",
        "    \n",
        "    output_corpus = list()\n",
        "    \n",
        "    for doc in corpus:\n",
        "    \n",
        "        output_tensor = torch.zeros(MAX_LENGTH, dtype=torch.int64)\n",
        "\n",
        "        for index, token in enumerate(doc):\n",
        "            \n",
        "            if token in vocab:\n",
        "                output_tensor[index] = vocab[token]\n",
        "            else:\n",
        "                output_tensor[index] = vocab['<unk>']\n",
        "            \n",
        "        output_corpus.append(output_tensor)\n",
        "    \n",
        "    return torch.stack(output_corpus)\n",
        "\n",
        "src_train = document_vectorizer(train.english.to_list(), src_vocabulary)\n",
        "trg_train = document_vectorizer(train.german.to_list(), trg_vocabulary)\n",
        "\n",
        "src_val = document_vectorizer(val.english.to_list(), src_vocabulary)\n",
        "trg_val = document_vectorizer(val.german.to_list(), trg_vocabulary)\n",
        "\n",
        "src_test = document_vectorizer(test.english.to_list(), src_vocabulary)\n",
        "trg_test = document_vectorizer(test.german.to_list(), trg_vocabulary)\n",
        "\n",
        "print(f'>>> Train:\\n• src -> {src_train.shape}\\n• trg -> {trg_train.shape}')\n",
        "print(f'\\n>>> Val.:\\n• src -> {src_val.shape}\\n• trg -> {trg_val.shape}')\n",
        "print(f'\\n>>> Test:\\n• src -> {src_test.shape}\\n• trg -> {trg_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNxvB7HvzgQP"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# Generate DataLoaders #\n",
        "########################\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "def dataloader_generator(src, trg, shuffle):\n",
        "\n",
        "    dataset = torch.utils.data.TensorDataset(src, trg)\n",
        "    return torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                       num_workers=8,\n",
        "                                       shuffle=shuffle,\n",
        "                                       batch_size=BATCH_SIZE)\n",
        "\n",
        "train_dataloader = dataloader_generator(src_train, trg_train, True)\n",
        "val_dataloader = dataloader_generator(src_val, trg_val, False)\n",
        "test_dataloader = dataloader_generator(src_test, trg_test, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FiEwNlUzgQQ"
      },
      "source": [
        "# 3. Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmwBw130zgQR"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# Import #\n",
        "##########\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F \n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1wHPu1gzgQR"
      },
      "source": [
        "## 3.1 Encoder\n",
        "\n",
        "<table class=\"image\">\n",
        "<center>\n",
        "<caption align=\"bottom\">(Trevett, n.d.)</caption>\n",
        "<tr><td><img width=512 src='https://git.uni-paderborn.de/data.analytics.teaching/aml4ta-2020/-/raw/master/week_6/images/trevett_encoder.png'></td></tr>\n",
        "</center>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQbgn_7wzgQS"
      },
      "outputs": [],
      "source": [
        "###########\n",
        "# Encoder #\n",
        "###########\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers=1, dropout=0., bidirectional=True):\n",
        "        \n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Define embedding layer (vocab_size, emb_dim)\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        \n",
        "        # Define recurrent layer (emb_dim, hidden_dim, *)\n",
        "        # Example -> Bidirectional GRU\n",
        "        self.rnn = nn.GRU(\n",
        "            emb_dim, \n",
        "            hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        \n",
        "    def forward(self, input):\n",
        "                \n",
        "        # Embedding layer\n",
        "        # Input -> (sequence_length, batch_size)\n",
        "        embedding = self.embedding(input)\n",
        "                        \n",
        "        # Recurrent layer\n",
        "        # Input -> (sequence_length, batch_size, embedding_dim)\n",
        "        _, hidden_state = self.rnn(embedding)\n",
        "        \n",
        "        # Return hidden state\n",
        "        # Output -> (n_layers * directions, batch_size, hidden_dim)\n",
        "        return hidden_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEzqzk6pzgQT"
      },
      "outputs": [],
      "source": [
        "#################\n",
        "# Debug encoder #\n",
        "#################\n",
        "\n",
        "DEBUG_BATCH_SIZE = 5\n",
        "\n",
        "debug_encoder = Encoder(len(src_vocabulary)+1, 200, 256, 1, 0., False)\n",
        "hidden_state = debug_encoder.forward(src_train[:DEBUG_BATCH_SIZE].permute(1,0))\n",
        "hidden_state.shape\n",
        "# Debugging\n",
        "# (if required!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hAa2Kh0zgQT"
      },
      "source": [
        "## 3.2 Decoder\n",
        "\n",
        "<table class=\"image\">\n",
        "<center>\n",
        "<caption align=\"bottom\">(Trevett, n.d.)</caption>\n",
        "<tr><td><img width=256 src='https://git.uni-paderborn.de/data.analytics.teaching/aml4ta-2020/-/raw/master/week_6/images/trevett_decoder.png'></td></tr>\n",
        "</center>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu2pite0zgQU"
      },
      "outputs": [],
      "source": [
        "###########\n",
        "# Decoder #\n",
        "###########\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers=1, dropout=0., bidirectional=True):\n",
        "        \n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # Define embedding layer (vocab_size, emb_dim)\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        \n",
        "        # Define recurrent layer (emb_dim, hidden_dim, *)\n",
        "        # Example -> Bidirectional GRU\n",
        "        self.rnn = nn.GRU(\n",
        "            emb_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        \n",
        "        # Define fully connected layer (hidden_dim * directions, vocab_size)\n",
        "        self.out = nn.Linear(hidden_dim * (2 if bidirectional else 1), vocab_size)\n",
        "                            \n",
        "    def forward(self, input, hidden_state):\n",
        "        \n",
        "        # Add dimension at position 0\n",
        "        # Input -> (batch_size)\n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        # Embedding layer\n",
        "        # Input -> (1, batch_size)\n",
        "        embedded = self.embedding(input)\n",
        "                \n",
        "        # Recurrent layer\n",
        "        # Input -> (sequence_length, batch_size, embedding_dim)\n",
        "        output, hidden_state = self.rnn(embedded, hidden_state)\n",
        "        \n",
        "        # FCL\n",
        "        # Input -> (sequence_length, batch_size, hidden_dim * directions)\n",
        "        predictions = self.out(output).squeeze(0)\n",
        "        \n",
        "        # Return prediction + hidden_state\n",
        "        # Prediction -> (batch_size, vocab_size)\n",
        "        return predictions, hidden_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xanLdmlBzgQU"
      },
      "outputs": [],
      "source": [
        "#################\n",
        "# Debug encoder #\n",
        "#################\n",
        "\n",
        "DEBUG_BATCH_SIZE = 5\n",
        "\n",
        "debug_encoder = Encoder(len(src_vocabulary)+1, 200, 256, 1, 0., True)\n",
        "hidden_state = debug_encoder.forward(src_train[:DEBUG_BATCH_SIZE].permute(1,0))\n",
        "\n",
        "debug_decoder = Decoder(len(trg_vocabulary)+1, 200, 256, 1, 0., True)\n",
        "prediction, hidden_state = debug_decoder.forward(trg_train[:DEBUG_BATCH_SIZE].permute(1,0)[0], hidden_state)\n",
        "\n",
        "# Debugging\n",
        "# (if required!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dctH0YtizgQV"
      },
      "source": [
        "## 3.3 Model\n",
        "\n",
        "<table class=\"image\">\n",
        "<center>\n",
        "<caption align=\"bottom\">(Trevett, n.d.)</caption>\n",
        "<tr><td><img width=512 src='https://git.uni-paderborn.de/data.analytics.teaching/aml4ta-2020/-/raw/master/week_6/images/trevett_seq2seq.png'></td></tr>\n",
        "</center>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh5cKkk4zgQV"
      },
      "outputs": [],
      "source": [
        "#########\n",
        "# Model #\n",
        "#########\n",
        "\n",
        "class Model(nn.Module):\n",
        "    \n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        \n",
        "        # Initialize output vector (sequence_length, batch_size, vocab_size)\n",
        "        output_vector = torch.zeros(trg.shape[0], trg.shape[1], self.decoder.vocab_size).to(self.device)\n",
        "        \n",
        "        # Encoder\n",
        "        # Input -> (sequence_length, batch_size)\n",
        "        hidden_state = self.encoder(src)\n",
        "        \n",
        "        # First token (i.e., <sos>)\n",
        "        # Input -> (sequence_length, batch_size)\n",
        "        # Output -> (batch_size)\n",
        "        decoder_input = trg[0]\n",
        "                \n",
        "        for index in range(1, trg.shape[0]):\n",
        "            \n",
        "            # Decoder\n",
        "            # Input -> (batch_size)\n",
        "            # Hidden state -> tensor (e.g., RNN / GRU) or tuple (e.g., LSTM)\n",
        "            predictions, hidden_state = self.decoder(decoder_input, hidden_state)\n",
        "\n",
        "            # Append \n",
        "            output_vector[index] = predictions\n",
        "                        \n",
        "            # Teacher forcing\n",
        "            teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "            decoder_input = trg[index] if teacher_forcing else torch.argmax(predictions, dim=1)\n",
        "            \n",
        "        # Return output_vector\n",
        "        # Output -> (sequence_length, batch_size, trg_vocab_size)\n",
        "        return output_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAXld6zXzgQW"
      },
      "outputs": [],
      "source": [
        "#################\n",
        "# Debug model #\n",
        "#################\n",
        "\n",
        "DEBUG_BATCH_SIZE = 2\n",
        "\n",
        "debug_encoder = Encoder(len(src_vocabulary), 200, 256, 1, 0., True)\n",
        "debug_decoder = Decoder(len(trg_vocabulary), 200, 256, 1, 0., True)\n",
        "\n",
        "debug_model = Model(debug_encoder, debug_decoder, 'cpu')\n",
        "\n",
        "output_vector = debug_model.forward(src_train[:DEBUG_BATCH_SIZE].permute(1,0),\n",
        "                                    trg_train[:DEBUG_BATCH_SIZE].permute(1,0), \n",
        "                                    teacher_forcing_ratio=0.5)\n",
        "\n",
        "# Debugging\n",
        "# (if required!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skJFWnmEzgQW"
      },
      "source": [
        "## 3.4 Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJEMqUDHzgQW"
      },
      "outputs": [],
      "source": [
        "####################\n",
        "# Initialize model #\n",
        "####################\n",
        "\n",
        "# Hyperparameters\n",
        "EMB_DIM = 300\n",
        "HIDDEN_DIM = 512\n",
        "NUM_LAYERS = 1\n",
        "DROPOUT = 0.\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "# Encoder\n",
        "encoder = Encoder(len(src_vocabulary)+1, EMB_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT, BIDIRECTIONAL)\n",
        "\n",
        "# Decoder\n",
        "decoder = Decoder(len(trg_vocabulary)+1, EMB_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT, BIDIRECTIONAL)\n",
        "\n",
        "# Model\n",
        "model = Model(encoder, decoder, device)\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(),lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "# Loss function (a.k.a. criterion)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2vGjMkXzgQX"
      },
      "outputs": [],
      "source": [
        "#######################\n",
        "# Evaluation function #\n",
        "#######################\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    total_loss = 0\n",
        "    \n",
        "    for batch_id, batch in enumerate(dataloader):\n",
        "\n",
        "        # Get validation/test data\n",
        "        src, trg = batch\n",
        "\n",
        "        # Permute dimensions\n",
        "        # Input -> (batch_size, sequence_length)\n",
        "        # Output -> (sequence_length, batch_size)\n",
        "        src = src.permute(1,0).to(device)\n",
        "        trg = trg.permute(1,0).to(device)\n",
        "         \n",
        "        with torch.no_grad():\n",
        "            \n",
        "            # Encoder\n",
        "            hidden_state = model.encoder(src)\n",
        "\n",
        "            # Initialize output vector (sequence_length, batch_size, vocab_size)\n",
        "            outputs = torch.zeros(src.shape[0], src.shape[1], model.decoder.vocab_size).to(device)\n",
        "\n",
        "            # First token (i.e., <sos>)    \n",
        "            decoder_input = src[0]\n",
        "\n",
        "            for index in range(1, src.shape[0]):\n",
        "                predictions, hidden_state = model.decoder(decoder_input, hidden_state)\n",
        "                outputs[index] = predictions\n",
        "                decoder_input = torch.argmax(predictions, dim=1)\n",
        "\n",
        "        # Skip first token (i.e., <sos>) + reshape output\n",
        "        # Input -> (sequence_length, batch_size, trg_vocab_size)\n",
        "        # Output -> (sequence_length-1 * batch_size, trg_vocab_size)\n",
        "        outputs = outputs[1:].reshape(-1, outputs.shape[2])\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, trg[1:].reshape(-1))\n",
        "\n",
        "        # Update loss\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5bRvAaLzgQY"
      },
      "outputs": [],
      "source": [
        "###############\n",
        "# Train model #\n",
        "###############\n",
        "\n",
        "EPOCHS = 15\n",
        "\n",
        "train_history = list()\n",
        "validation_history = list()\n",
        "\n",
        "best_validation_loss = np.inf\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    model.train()\n",
        "        \n",
        "    total_loss = 0\n",
        "        \n",
        "    for batch_id, batch in enumerate(train_dataloader):\n",
        "        \n",
        "        # Get training data\n",
        "        src, trg = batch\n",
        "        \n",
        "        # Permute dimensions\n",
        "        # Input -> (batch_size, sequence_length)\n",
        "        # Output -> (sequence_length, batch_size)\n",
        "        src = src.permute(1,0).to(device)\n",
        "        trg = trg.permute(1,0).to(device)\n",
        "  \n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Feedforward\n",
        "        # teacher_forcing_ratio >= 0.0\n",
        "        outputs = model(src, trg, teacher_forcing_ratio=0.4)\n",
        "               \n",
        "        # Skip first token (i.e., <sos>) + reshape output\n",
        "        # Input -> (sequence_length, batch_size, trg_vocab_size)\n",
        "        # Output -> (sequence_length-1 * batch_size, trg_vocab_size)\n",
        "        outputs = outputs[1:].reshape(-1, outputs.shape[2])\n",
        "                        \n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, trg[1:].reshape(-1))\n",
        "        \n",
        "        # Backpropagate errors\n",
        "        loss.backward()\n",
        "        \n",
        "        # Clip gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update loss\n",
        "        total_loss =+ loss.item()\n",
        "        \n",
        "    # Validation\n",
        "    validation_loss = evaluate(model, val_dataloader, criterion)\n",
        "    \n",
        "    if validation_loss < best_validation_loss:\n",
        "\n",
        "        best_validation_loss = validation_loss\n",
        "        torch.save(model, 'best_seq2seq_model.pt')\n",
        "    \n",
        "    train_history.append(total_loss)\n",
        "    validation_history.append(validation_loss)\n",
        "    \n",
        "    print({ 'epoch': epoch, 'training loss': total_loss, 'validation loss': validation_loss})\n",
        "\n",
        "print('\\n>>> DONE!')\n",
        "print(f'>>> BEST MODEL (VALIDATION): {best_validation_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP8Iw2l-zgQY"
      },
      "outputs": [],
      "source": [
        "################\n",
        "# Plot history #\n",
        "################\n",
        "\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
        "\n",
        "axs[0].plot(train_history)\n",
        "axs[0].set_title('Training Loss')\n",
        "\n",
        "axs[1].plot(validation_history)\n",
        "axs[1].set_title('Validation Loss')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-4LOyxmzgQY"
      },
      "source": [
        "## 3.5 Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxpefPdxzgQZ"
      },
      "outputs": [],
      "source": [
        "#########################\n",
        "# Evaluate model (test) #\n",
        "#########################\n",
        "\n",
        "# Load model\n",
        "best_model = torch.load('best_seq2seq_model.pt')\n",
        "\n",
        "# Evaluate\n",
        "print(evaluate(best_model, test_dataloader, criterion))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlAR_Z8xzgQa"
      },
      "outputs": [],
      "source": [
        "#############\n",
        "# Translate #\n",
        "#############\n",
        "\n",
        "def get_translation(document, seq2seq_model):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        # Add dimension\n",
        "        document = document.unsqueeze(1)\n",
        "        \n",
        "        # Encoder\n",
        "        hidden_state = seq2seq_model.encoder(document.to(device))\n",
        "        \n",
        "        # Initialize output document\n",
        "        output_document = [trg_vocabulary['<sos>']]\n",
        "\n",
        "        for _ in range(1, src.shape[0]):\n",
        "                        \n",
        "            outputs, hidden_state = seq2seq_model.decoder(torch.LongTensor([output_document[-1]]).to(device), hidden_state)            \n",
        "            output_document.append(outputs.argmax().item())\n",
        "            \n",
        "            if output_document[-1] == trg_vocabulary['<eos>']:\n",
        "                break\n",
        "            \n",
        "        return output_document\n",
        "\n",
        "def tokens_lookup(tokens_idx, vocabulary):\n",
        "    tokens = [list(vocabulary.keys())[list(vocabulary.values()).index(token)] for token in tokens_idx if token != vocabulary['<pad>']]\n",
        "    return ' '.join(tokens)\n",
        "        \n",
        "# Document ID\n",
        "ID = 13 # 442 # 178\n",
        "\n",
        "# Translate\n",
        "tokens_idx = get_translation(src_test[ID], best_model)\n",
        "translation = tokens_lookup(tokens_idx, trg_vocabulary)\n",
        "print(f'>>> Translation: {translation}')\n",
        "\n",
        "# Source & Target\n",
        "print(f'\\n>>> Source: {tokens_lookup(src_test[ID].tolist(), src_vocabulary)}')\n",
        "print(f'>>> Target: {tokens_lookup(trg_test[ID].tolist(), trg_vocabulary)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xySzdO6UzgQb"
      },
      "source": [
        "<ul style=\"list-style-type:round\">\n",
        "<i>\n",
        "    <li>Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., &amp; Bengio, Y. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation.</li>\n",
        "    <li>Lane, H., Howard, C., &amp; Hapke, H.M. (2019). Natural Language Processing in Action. Shelter Island, NY: Manning Publications Co.</li>\n",
        "    <li>Rao, D., &amp; McMahan, B. (2019). Natural Language Processing with Pytorch. Sebastopol, CA: O'Reilly Media.</li>\n",
        "    <li>Robertson, S. (n.d.). NLP from Scratch: Translation with a Sequence-to-Sequence Network and Attention. <a href=\"https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\">Link</a>.</li>\n",
        "    <li>Trevett, B. (n.d.). pytorch-seq2seq:  Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. <a href=\"https://github.com/bentrevett/pytorch-seq2seq/blob/master/2%20-%20Learning%20Phrase%20Representations%20using%20RNN%20Encoder-Decoder%20for%20Statistical%20Machine%20Translation.ipynb\">Link</a>.</li>\n",
        "</i>\n",
        "</ul>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "08_sequence2sequence_FULL.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}