{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "2.03 - Multi-class classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olivermueller/aml4ta-2021/blob/main/Session_02/2_03_Multi_class_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJrKCbjZsqpo"
      },
      "source": [
        "# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pblMcujrVt7-"
      },
      "source": [
        "# Set up Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NpTS4Z2Vvzy"
      },
      "source": [
        "# Install packages\n",
        "!pip install pymysql"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-DU0hkyVyPi"
      },
      "source": [
        "# <font color=\"#003660\">Week 2: Predicting with Bags of Words</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhy42GjRV3ON"
      },
      "source": [
        "# <font color=\"#003660\">Notebook 3: Multi-class Classification</font>\n",
        "\n",
        "<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n",
        "\n",
        "<p>\n",
        "<center>\n",
        "<div>\n",
        "    <font color=\"#085986\"><b>By the end of this lesson, you will be able to...</b><br><br>\n",
        "        ... transform raw text into a term-document matrix, <br>\n",
        "        ... train a binary classifier on the term-document matrix, and <br> ... and compete in a Kaggle competition.\n",
        "    </font>\n",
        "</div>\n",
        "</center>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6vVpwIFsqps"
      },
      "source": [
        "# Import packages\n",
        "\n",
        "As always, we first need to load a number of required Python packages:\n",
        "- `pandas` provides high-performance, easy-to-use data structures and data analysis tools.\n",
        "- `SQLAlchemy`, together with `pymysql`, allows to communicate with SQL databases.\n",
        "- `getpass` provides function to safely enter passwords.\n",
        "- `spacy` offers industrial-strength natural language processing.\n",
        "- `sklearn` is the de-facto standard machine learning package in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMrhkr83sqpt"
      },
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "import getpass\n",
        "import spacy\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZd82t53sqpu"
      },
      "source": [
        "# Load documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsrCafxksqpv"
      },
      "source": [
        "We load our data from a MySQL database. For security reasons, we don't store the database credentials here; please have a look at Panda to get them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSIGfKcXsqpv"
      },
      "source": [
        "# Get credentials\n",
        "user = input(\"Username: \")\n",
        "passwd = getpass.getpass(\"Password: \")\n",
        "server = input(\"Server: \")\n",
        "db = input(\"Database: \")\n",
        "\n",
        "# Create an engine instance (SQLAlchemy)\n",
        "engine = create_engine(\"mysql+pymysql://{}:{}@{}/{}\".format(user, passwd ,server, db))\n",
        "\n",
        "# Define SQL query\n",
        "sql_query = \"SELECT * FROM WineDataset\"\n",
        "\n",
        "# Query dataset (pandas)\n",
        "corpus = pd.read_sql(sql=sql_query, con=engine)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlZ90YoJDiYr"
      },
      "source": [
        "top_countries = [\"US\",\"France\",\"Italy\",\"Spain\",\"Portugal\",\"Chile\",\"Argentina\",\"Austria\",\"Australia\",\"Germany\"]\n",
        "corpus = corpus[corpus[\"country\"].isin(top_countries)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMzZ9re_yY5K"
      },
      "source": [
        "corpus.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NsIQrLiSEak"
      },
      "source": [
        "corpus.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v8oiPAcsqpx"
      },
      "source": [
        "# Preprocess documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7psnR5cmQLBx"
      },
      "source": [
        "Split data into training, validation, and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSObnTaWdgdM"
      },
      "source": [
        "training = corpus[corpus[\"testset\"] == 0]\n",
        "validation = training.iloc[80000:100000,]\n",
        "training = training.iloc[0:80000,]\n",
        "test = corpus[corpus[\"testset\"] == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m05pjMr8Rvxs"
      },
      "source": [
        "print(training.shape)\n",
        "print(validation.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSrHVdoZsqpy"
      },
      "source": [
        "Perform standard NLP preprocessing steps on the training set using spaCy. To speed up things, we disable some components of spaCy's standard NLP pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh4KVmP6sqpy"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'tagger'])\n",
        "\n",
        "def spacy_prep(dataset):\n",
        "  dataset = dataset.to_dict(\"records\")\n",
        "  for i, entry in enumerate(dataset):\n",
        "      text = nlp(entry[u'description'])\n",
        "      tokens_to_keep = []\n",
        "      for token in text:\n",
        "          if token.is_alpha and not token.is_stop:\n",
        "              tokens_to_keep.append(token.lemma_.lower())\n",
        "      entry[u'description_prep'] = \" \".join(tokens_to_keep)\n",
        "  dataset = pd.DataFrame(dataset)\n",
        "  return(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4rKCZRs9tlj"
      },
      "source": [
        "training = spacy_prep(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tothp_Ssqpz"
      },
      "source": [
        "Display the first couple of lines of the preprocessed descriptions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyLoiearsqpz"
      },
      "source": [
        "training[\"description_prep\"].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYQppmeBQUtX"
      },
      "source": [
        "# Vectorize documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAXDnM1Hsqp1"
      },
      "source": [
        "Use a `CountVectorizer` to vectorize the documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbeTq9S9sqp1"
      },
      "source": [
        "count_vect = CountVectorizer(min_df=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06DEGrExsqp1"
      },
      "source": [
        "Apply the vectorizer to the review texts of the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AemriJOAsqp1"
      },
      "source": [
        "X_training = count_vect.fit_transform(training[\"description_prep\"].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QTlJ4BDsqp3"
      },
      "source": [
        "Store the labels that we want to predict in a separate variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUpaU5Pgsqp3"
      },
      "source": [
        "y_training = training[\"country\"]\n",
        "y_training.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv9OfHjwE73o"
      },
      "source": [
        "A simple way to extend binary classification algorithms to the multi-class classification case is to use the so-called **one-vs-rest scheme**. The simple idea is to learn one binary classifier per class. For doing so, we need to convert multi-class labels to multiple binary labels (belong or does not belong to the class)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG6P6mQpDS70"
      },
      "source": [
        "label_bin = LabelBinarizer().fit(y_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYZTEQ1aEt62"
      },
      "source": [
        "y_training_bin = label_bin.transform(y_training)\n",
        "y_training_bin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biwWaNjNsqp4"
      },
      "source": [
        "# Train classifier on training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTHaUsAosqp4"
      },
      "source": [
        "Use the `OneVsRestClassifier` wrapper to fit one logistic regression classifier per class. The term-document matrix holds the features and the binarized country of origin (i.e., `country` variable) represents the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZkAh7oesqp4"
      },
      "source": [
        "clf = OneVsRestClassifier(LogisticRegression(max_iter=1000)).fit(X_training, y_training_bin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuAVWgC8sqp4"
      },
      "source": [
        "Test whether classifier is working by predicting the quality of a short fake review. We apply the same NLP preprocessing steps and reuse the `count_vect` object to generate features in the same way as we did for the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrjU4Uj4-jpx"
      },
      "source": [
        "doc_new = {'index': [1], \n",
        "           'description': ['This is a good wine']}\n",
        "\n",
        "doc_new_df = pd.DataFrame.from_dict(doc_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B16iOiWsqp5"
      },
      "source": [
        "doc_new_df_prep = spacy_prep(doc_new_df)\n",
        "doc_new_df_prep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVtvBRIXGktZ"
      },
      "source": [
        "Predict class membership. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sD7SeyD4nig"
      },
      "source": [
        "X_new = count_vect.transform(doc_new_df_prep[\"description_prep\"])\n",
        "predicted = clf.predict(X_new)\n",
        "predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O0CDqPjGtJz"
      },
      "source": [
        "label_bin.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMp87EJTHfhZ"
      },
      "source": [
        "label_bin.inverse_transform(predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6zZzlq4sqp5"
      },
      "source": [
        "Instead of predicting hard membership, we can also predict the probabilities of the classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks6yRPyEsqp5"
      },
      "source": [
        "predicted_prob = clf.predict_proba(X_new)\n",
        "print(clf.classes_)\n",
        "print(predicted_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPkryHMHHlLz"
      },
      "source": [
        "label_bin.inverse_transform(predicted_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "663LU5XQsqp5"
      },
      "source": [
        "# Evaluate accuracy on validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8-z8rqVsqp6"
      },
      "source": [
        "Let's evaluate the predictive accurcay of our model on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCZDzJOR51SZ"
      },
      "source": [
        "validation = spacy_prep(validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiUIhoK0sqp6"
      },
      "source": [
        "X_validation = count_vect.transform(validation[\"description_prep\"])\n",
        "y_validation = validation[\"country\"]\n",
        "y_validation_bin = label_bin.transform(y_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4upAshmAsqp6"
      },
      "source": [
        "Call the predict function of our model with the validation data and calculate precision, recall and F1-score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ngkprkgsqp6"
      },
      "source": [
        "predictions_validation = clf.predict(X_validation)\n",
        "print(metrics.classification_report(y_validation_bin, predictions_validation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgI1kPv6cKkU"
      },
      "source": [
        "# Interpret model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fEkRUPEcPAW"
      },
      "source": [
        "Interpretation of a one-vs-rest logistic regression classifier is a bit more complex as usual, as we have to inspect the coefficients of many models (i.e., one per class)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yx40Me_bXdF"
      },
      "source": [
        "coeffs = clf.coef_[6].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xTsCyZWbokF"
      },
      "source": [
        "words = count_vect.get_feature_names()\n",
        "words_with_coeffs = pd.DataFrame(coeffs, words, columns=[\"coeff\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v21YzlRbb1gI"
      },
      "source": [
        "words_with_coeffs.sort_values(\"coeff\", ascending=True).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SPNOsuGb45e"
      },
      "source": [
        "words_with_coeffs.sort_values(\"coeff\", ascending=False).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmwoET1Yb6rd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}